{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":25954,"databundleVersionId":2091745,"sourceType":"competition"},{"sourceId":33246,"databundleVersionId":3221581,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Create MelSpectograms from 2022 BirdClef data","metadata":{}},{"cell_type":"markdown","source":"This notebook is based on Kkiller Mels Computer from 2021","metadata":{}},{"cell_type":"markdown","source":"### Setup and config","metadata":{}},{"cell_type":"code","source":"###############\n### Imports ###\n###############\n\nimport joblib, json\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport librosa\nimport librosa.display\nimport soundfile\nfrom  soundfile import SoundFile\nfrom  IPython.display import Audio\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\n\nfrom  sklearn.model_selection  import StratifiedKFold","metadata":{"id":"2dt7oG43VAqc","execution":{"iopub.status.busy":"2024-06-15T15:51:10.607161Z","iopub.execute_input":"2024-06-15T15:51:10.608489Z","iopub.status.idle":"2024-06-15T15:51:10.616648Z","shell.execute_reply.started":"2024-06-15T15:51:10.608423Z","shell.execute_reply":"2024-06-15T15:51:10.614589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"fJB9IS2RVAqe","execution":{"iopub.status.busy":"2024-06-15T15:45:42.007853Z","iopub.execute_input":"2024-06-15T15:45:42.008347Z","iopub.status.idle":"2024-06-15T15:45:42.016276Z","shell.execute_reply.started":"2024-06-15T15:45:42.008313Z","shell.execute_reply":"2024-06-15T15:45:42.014919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#################\n### Constants ###\n#################\nSTART_INDEX = 0  # The file index in the metadata to start from \nEND_INDEX = 14852  # The end index. 14852 is maximal\n\n\n##############\n### Config ###\n##############\nSR = 32_000  # sample rate\nDURATION = 7\nSEED = 261\n\nN_FFT = SR // 10\nHOP_LENGTH = SR // (10 * 4)\n\nFMIN = 0\nFMAX = SR // 2\nN_MELS = 128\n\n#############\n### PATHS ###\n#############\nDATA_ROOT = Path(\"../input/birdclef-2022\")\nTRAIN_AUDIO_ROOT = Path(\"../input/birdclef-2022/train_audio\")\nTRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"audio_images\") # Where to save the mels images\nTRAIN_AUDIO_IMAGES_SAVE_ROOT.mkdir(exist_ok=True, parents=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:51:15.144667Z","iopub.execute_input":"2024-06-15T15:51:15.145233Z","iopub.status.idle":"2024-06-15T15:51:15.153149Z","shell.execute_reply.started":"2024-06-15T15:51:15.145070Z","shell.execute_reply":"2024-06-15T15:51:15.151818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"def get_audio_info(filepath):\n    \"\"\"Get some properties from  an audio file\"\"\"\n    with SoundFile(filepath) as f:\n        sr = f.samplerate\n        frames = f.frames\n        duration = float(frames)/sr\n    return {\"frames\": frames, \"sr\": sr, \"duration\": duration}","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:52:29.260816Z","iopub.execute_input":"2024-06-15T15:52:29.261243Z","iopub.status.idle":"2024-06-15T15:52:29.267596Z","shell.execute_reply.started":"2024-06-15T15:52:29.261210Z","shell.execute_reply":"2024-06-15T15:52:29.266360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_meta_df(n_splits=5, seed=SEED, nrows=None):\n    df = pd.read_csv(DATA_ROOT/\"train_metadata.csv\", nrows=nrows)\n    label_ids = {label: label_id for label_id,label in enumerate(sorted(df[\"primary_label\"].unique()))}\n    \n    # get fully / partial data from df based on the given desired indexes\n    df = df.iloc[START_INDEX: END_INDEX]\n\n    # add umeric label and path to the df\n    df[\"label_id\"] = df[\"primary_label\"].map(label_ids)\n    df[\"filepath\"] = [str(TRAIN_AUDIO_ROOT/filename) for primary_label,filename in zip(df.primary_label, df.filename) ]\n\n    # get audio info for ogg files\n    pool = joblib.Parallel(4)\n    mapper = joblib.delayed(get_audio_info)\n    tasks = [mapper(filepath) for filepath in df.filepath] # tasks will include sr, frames, duration for each filepath\n    df = pd.concat([df, pd.DataFrame(pool(tqdm(tasks)))], axis=1, sort=False)\n    \n    # provides train/test indices to split data in train/test sets.\n    skf = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n    splits = skf.split(np.arange(len(df)), y=df.label_id.values)\n    df[\"fold\"] = -1\n\n    for fold, (train_set, val_set) in enumerate(splits): \n        df.loc[df.index[val_set], \"fold\"] = fold\n\n    return label_ids, df","metadata":{"id":"Kmh6xx5_NCjJ","outputId":"ad61f09f-6f0e-4204-c658-21112e051785","execution":{"iopub.status.busy":"2024-06-15T15:52:31.456661Z","iopub.execute_input":"2024-06-15T15:52:31.457104Z","iopub.status.idle":"2024-06-15T15:52:31.467433Z","shell.execute_reply.started":"2024-06-15T15:52:31.457069Z","shell.execute_reply":"2024-06-15T15:52:31.466054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract Metadata ","metadata":{}},{"cell_type":"code","source":"# save enriched metadata and labels mapping to files\nLABEL_IDS, meta_df = create_meta_df(nrows=None)\n\nmeta_df.to_csv(\"rich_train_metadata.csv\", index=True)\nwith open(\"LABEL_IDS.json\", \"w\") as f:\n    json.dump(LABEL_IDS, f)\n\nmeta_df.head()","metadata":{"id":"SRRhx1EAN75G","outputId":"f1688387-b564-4f8d-8895-4490c90d4150","execution":{"iopub.status.busy":"2024-06-15T15:52:39.079731Z","iopub.execute_input":"2024-06-15T15:52:39.080272Z","iopub.status.idle":"2024-06-15T15:52:50.324301Z","shell.execute_reply.started":"2024-06-15T15:52:39.080237Z","shell.execute_reply":"2024-06-15T15:52:50.323008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data statistics","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num of audio files in every fold\nmeta_df[\"fold\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num of train files per labels\nmeta_df[\"primary_label\"].value_counts()","metadata":{"id":"ZRz-DwbNVAqg","outputId":"51f26b97-6a1e-4e39-c6fa-5114cfe27a25","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data duration histogram\nmeta_df[\"duration\"].hist(bins=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df[\"duration\"].quantile(np.arange(0, 1, 0.01)).plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"xh4hfWZhuglm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MelSpectogram Computer\nclass for casting audio data to melspectogram","metadata":{}},{"cell_type":"code","source":"def compute_mel(audio, sr=SR, n_mels=N_MELS, fmin=FMIN, fmax=FMAX, n_fft=N_FFT, hop_length=HOP_LENGTH):\n    melspec = librosa.feature.melspectrogram(\n        y=audio, \n        sr=sr, \n        n_mels=n_mels, \n        fmin=fmin, \n        fmax=fmax,\n        n_fft=n_fft,\n        hop_length=hop_length\n    )\n\n    melspec = librosa.power_to_db(melspec).astype(np.float32)\n    return melspec","metadata":{"id":"7NZq43qTVAqi","execution":{"iopub.status.busy":"2024-06-15T15:52:56.086185Z","iopub.execute_input":"2024-06-15T15:52:56.086597Z","iopub.status.idle":"2024-06-15T15:52:56.094090Z","shell.execute_reply.started":"2024-06-15T15:52:56.086564Z","shell.execute_reply":"2024-06-15T15:52:56.092660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utils for mels data edit","metadata":{}},{"cell_type":"code","source":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    # normalize\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) / (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) / (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\n# used to make all data vectors in the same length\ndef crop_or_pad(y, length, is_train=True, start=None):\n    if len(y) < length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n        \n        n_repeats = length // len(y)\n        epsilon = length % len(y)\n        \n        y = np.concatenate([y]*n_repeats + [y[:epsilon]])\n        \n    elif len(y) > length:\n        if not is_train:\n            start = start or 0\n        else:\n            start = start or np.random.randint(len(y) - length)\n\n        y = y[start:start + length]\n\n    return y","metadata":{"id":"-Nlw4E5UVAqi","execution":{"iopub.status.busy":"2024-06-15T15:52:59.674491Z","iopub.execute_input":"2024-06-15T15:52:59.675084Z","iopub.status.idle":"2024-06-15T15:52:59.685934Z","shell.execute_reply.started":"2024-06-15T15:52:59.675044Z","shell.execute_reply":"2024-06-15T15:52:59.684484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create mels from audio","metadata":{}},{"cell_type":"code","source":"def audio_to_image(audio):\n    melspec = compute_mel(audio) \n    image = mono_to_color(melspec)\n    return image\n        \ndef process_audio_files(row, duration=DURATION, sr=SR, res_type=\"kaiser_fast\",\n                        resample=True, save=True, step=None):\n    audio_length = duration * sr\n    step = step or audio_length\n    \n    # convert ogg to audio format\n    audio, orig_sr = soundfile.read(row.filepath, dtype=\"float32\")\n    \n    # if stereo - convert ro mono\n    if np.ndim(audio)>1:\n        audio = np.mean(audio, axis=1)\n\n    # resample if audio sr is not desired sr\n    if resample and orig_sr != sr:\n        audio = librosa.resample(audio, orig_sr, sr, res_type=res_type)\n    \n    # split long audio to shorter, same length parts.\n    audios = [audio[i:i + audio_length] for i in range(0, max(1, len(audio) - audio_length + 1), step)]\n    \n    # crop or pad last part\n    audios[-1] = crop_or_pad(audios[-1] , length=audio_length)\n    \n    # convert sudio parts to image\n    images = [audio_to_image(audio) for audio in audios]\n    \n    # cobine all parts together - for easyier saving\n    images = np.stack(images)\n    \n    # save or return images as np arrays\n    if save:\n        path = TRAIN_AUDIO_IMAGES_SAVE_ROOT/f\"{row.filename}.npy\"\n        path.parent.mkdir(exist_ok=True, parents=True)\n        np.save(str(path), images)\n    else:\n        return row.filename, images","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:53:03.531066Z","iopub.execute_input":"2024-06-15T15:53:03.532108Z","iopub.status.idle":"2024-06-15T15:53:03.543029Z","shell.execute_reply.started":"2024-06-15T15:53:03.532066Z","shell.execute_reply":"2024-06-15T15:53:03.541569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_audios_as_images(meta_df): \n    mapper = joblib.delayed(process_audio_files)\n    tasks = [mapper(row, step=int(DURATION*0.666*SR)) \n             for row in meta_df.itertuples(False)]\n    \n    joblib.Parallel(2)(tqdm(tasks))","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:53:08.103043Z","iopub.execute_input":"2024-06-15T15:53:08.103493Z","iopub.status.idle":"2024-06-15T15:53:08.113591Z","shell.execute_reply.started":"2024-06-15T15:53:08.103459Z","shell.execute_reply":"2024-06-15T15:53:08.111848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_audios_as_images(meta_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:53:24.202134Z","iopub.execute_input":"2024-06-15T15:53:24.202569Z","iopub.status.idle":"2024-06-15T15:53:42.355669Z","shell.execute_reply.started":"2024-06-15T15:53:24.202534Z","shell.execute_reply":"2024-06-15T15:53:42.353792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check output mels","metadata":{}},{"cell_type":"code","source":"row = meta_df.loc[meta_df.duration.idxmax()]\nmels = np.load(str((TRAIN_AUDIO_IMAGES_SAVE_ROOT/row.filename).as_posix() + \".npy\"))","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:53:57.228579Z","iopub.execute_input":"2024-06-15T15:53:57.229069Z","iopub.status.idle":"2024-06-15T15:53:57.239993Z","shell.execute_reply.started":"2024-06-15T15:53:57.229028Z","shell.execute_reply":"2024-06-15T15:53:57.238548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:55:44.167750Z","iopub.execute_input":"2024-06-15T15:55:44.168241Z","iopub.status.idle":"2024-06-15T15:55:44.177783Z","shell.execute_reply.started":"2024-06-15T15:55:44.168205Z","shell.execute_reply":"2024-06-15T15:55:44.176632Z"},"trusted":true},"execution_count":null,"outputs":[]}]}