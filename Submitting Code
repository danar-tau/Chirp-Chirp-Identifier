{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":33246,"databundleVersionId":3221581,"sourceType":"competition"},{"sourceId":1297722,"sourceType":"datasetVersion","datasetId":750498},{"sourceId":8664484,"sourceType":"datasetVersion","datasetId":5191819},{"sourceId":8674710,"sourceType":"datasetVersion","datasetId":5199467},{"sourceId":8674736,"sourceType":"datasetVersion","datasetId":5199489},{"sourceId":8675250,"sourceType":"datasetVersion","datasetId":5199870},{"sourceId":8714568,"sourceType":"datasetVersion","datasetId":5228315},{"sourceId":8714722,"sourceType":"datasetVersion","datasetId":5228429},{"sourceId":8758286,"sourceType":"datasetVersion","datasetId":5261788},{"sourceId":8758763,"sourceType":"datasetVersion","datasetId":5262152},{"sourceId":8758859,"sourceType":"datasetVersion","datasetId":5262222},{"sourceId":8714605,"sourceType":"datasetVersion","datasetId":5228333}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport json\nfrom pathlib import Path\nimport torch\nimport librosa as lb\nimport soundfile as sf\nfrom torch import nn\nfrom torch.utils.data import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-22T15:49:36.204565Z","iopub.execute_input":"2024-06-22T15:49:36.204864Z","iopub.status.idle":"2024-06-22T15:49:44.347924Z","shell.execute_reply.started":"2024-06-22T15:49:36.204837Z","shell.execute_reply":"2024-06-22T15:49:44.346949Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **INSTALLING RESNEST TO WORK IN OFFLINE MODE**","metadata":{}},{"cell_type":"code","source":"#copy resnest from dataset folder which is not exectuable to wokring dir\nif not os.path.exists(\"/kaggle/working/resnest\"):\n    !cp -r \"/kaggle/input/resnest50-fast-package/resnest-0.0.6b20200701/resnest\" \"/kaggle/working/resnest\"\n\n#installing resnest so it will work in offline kaggle mode\n!pip install --no-index \"/kaggle/working/resnest\" resnest\n\nimport resnest\nfrom resnest.torch import resnest50","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:49:44.349504Z","iopub.execute_input":"2024-06-22T15:49:44.349941Z","iopub.status.idle":"2024-06-22T15:50:02.940604Z","shell.execute_reply.started":"2024-06-22T15:49:44.349912Z","shell.execute_reply":"2024-06-22T15:50:02.939550Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing ./resnest\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from resnest==0.0.6b20240622) (1.26.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from resnest==0.0.6b20240622) (4.66.1)\nRequirement already satisfied: nose in /opt/conda/lib/python3.10/site-packages (from resnest==0.0.6b20240622) (1.3.7)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from resnest==0.0.6b20240622) (2.1.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from resnest==0.0.6b20240622) (9.5.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from resnest==0.0.6b20240622) (1.11.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from resnest==0.0.6b20240622) (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->resnest==0.0.6b20240622) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->resnest==0.0.6b20240622) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->resnest==0.0.6b20240622) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->resnest==0.0.6b20240622) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->resnest==0.0.6b20240622) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->resnest==0.0.6b20240622) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->resnest==0.0.6b20240622) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->resnest==0.0.6b20240622) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->resnest==0.0.6b20240622) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->resnest==0.0.6b20240622) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->resnest==0.0.6b20240622) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->resnest==0.0.6b20240622) (1.3.0)\nBuilding wheels for collected packages: resnest\n  Building wheel for resnest (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for resnest: filename=resnest-0.0.6b20240622-py3-none-any.whl size=31056 sha256=947771a56df90f4d63b2f3afca50bd822fb654c57fd59ac56b5a73ebf94da404\n  Stored in directory: /tmp/pip-ephem-wheel-cache-axifrh8n/wheels/60/c2/c1/2e6a36bd2bea1e189c937807a18e6afe693197d58b929ab9e5\nSuccessfully built resnest\nInstalling collected packages: resnest\nSuccessfully installed resnest-0.0.6b20240622\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Define Consts**","metadata":{}},{"cell_type":"code","source":"#paths and dataset\nTEST_FOLDER = '/kaggle/input/birdclef-2022/test_soundscapes/'\nPRED = {'row_id': [], 'target': []}\n\nbird_dict = {\"afrsil1\":0,\"akekee\":1,\"akepa1\":2,\"akiapo\":3,\"akikik\":4,\"amewig\":5,\"aniani\":6,\"apapan\":7,\"arcter\":8,\"barpet\":9,\"bcnher\":10,\"belkin1\":11,\"bkbplo\":12,\"bknsti\":13,\"bkwpet\":14,\"blkfra\":15,\"blknod\":16,\"bongul\":17,\"brant\":18,\"brnboo\":19,\"brnnod\":20,\"brnowl\":21,\"brtcur\":22,\"bubsan\":23,\"buffle\":24,\"bulpet\":25,\"burpar\":26,\"buwtea\":27,\"cacgoo1\":28,\"calqua\":29,\"cangoo\":30,\"canvas\":31,\"caster1\":32,\"categr\":33,\"chbsan\":34,\"chemun\":35,\"chukar\":36,\"cintea\":37,\"comgal1\":38,\"commyn\":39,\"compea\":40,\"comsan\":41,\"comwax\":42,\"coopet\":43,\"crehon\":44,\"dunlin\":45,\"elepai\":46,\"ercfra\":47,\"eurwig\":48,\"fragul\":49,\"gadwal\":50,\"gamqua\":51,\"glwgul\":52,\"gnwtea\":53,\"golphe\":54,\"grbher3\":55,\"grefri\":56,\"gresca\":57,\"gryfra\":58,\"gwfgoo\":59,\"hawama\":60,\"hawcoo\":61,\"hawcre\":62,\"hawgoo\":63,\"hawhaw\":64,\"hawpet1\":65,\"hoomer\":66,\"houfin\":67,\"houspa\":68,\"hudgod\":69,\"iiwi\":70,\"incter1\":71,\"jabwar\":72,\"japqua\":73,\"kalphe\":74,\"kauama\":75,\"laugul\":76,\"layalb\":77,\"lcspet\":78,\"leasan\":79,\"leater1\":80,\"lessca\":81,\"lesyel\":82,\"lobdow\":83,\"lotjae\":84,\"madpet\":85,\"magpet1\":86,\"mallar3\":87,\"masboo\":88,\"mauala\":89,\"maupar\":90,\"merlin\":91,\"mitpar\":92,\"moudov\":93,\"norcar\":94,\"norhar2\":95,\"normoc\":96,\"norpin\":97,\"norsho\":98,\"nutman\":99,\"oahama\":100,\"omao\":101,\"osprey\":102,\"pagplo\":103,\"palila\":104,\"parjae\":105,\"pecsan\":106,\"peflov\":107,\"perfal\":108,\"pibgre\":109,\"pomjae\":110,\"puaioh\":111,\"reccar\":112,\"redava\":113,\"redjun\":114,\"redpha1\":115,\"refboo\":116,\"rempar\":117,\"rettro\":118,\"ribgul\":119,\"rinduc\":120,\"rinphe\":121,\"rocpig\":122,\"rorpar\":123,\"rudtur\":124,\"ruff\":125,\"saffin\":126,\"sander\":127,\"semplo\":128,\"sheowl\":129,\"shtsan\":130,\"skylar\":131,\"snogoo\":132,\"sooshe\":133,\"sooter1\":134,\"sopsku1\":135,\"sora\":136,\"spodov\":137,\"sposan\":138,\"towsol\":139,\"wantat1\":140,\"warwhe1\":141,\"wesmea\":142,\"wessan\":143,\"wetshe\":144,\"whfibi\":145,\"whiter\":146,\"whttro\":147,\"wiltur\":148,\"yebcar\":149,\"yefcan\":150,\"zebdov\":151}\nreal_bird_dict = {}\nfor bird in bird_dict.keys():\n    real_bird_dict.update({bird_dict[bird] : bird})\nbird_dict = real_bird_dict\n\nCOMMON_BIRDS = [\"skylar\"]\nBIRDS_GROUP_DICT = {'skylar' : 0,  'houfin' : 0, 'jabwar' : 0, 'warwhe1' : 0, 'yefcan' : 0 \\\n                , 'apapan' : 1, 'iiwi' : 1, 'omao': 1, 'hawama' : 1, 'hawcre' : 1 \\\n                   , 'barpet' : 2, 'akiapo' : 2, 'elepai' : 2, 'aniani' : 2, 'hawgoo' : 2 \\\n                   , 'ercfra' : 3, 'hawpet1' : 3, 'puaioh' : 3, 'crehon' : 3, 'maupar' : 3}\nTHRESH_LIST = [0.15, 0.5, 0.3, 0.25]\n\n#MELSPECTOGRAM PARAMS\nSR = 32000\nDURATION = 5\nN_MELS = 128\nFMIN = 0\nFMAX = SR // 2\nN_FFT = SR // 10\nHOP_LENGTH = SR // (10 * 4)\n\n#Learning PARAMS\nTHRESH = 0.25\nPRECENTILE_THRESH = 85\nNUM_OF_BEST = 3\nMODIFIER = 0.7\n\n#MODEL PARAMS\nNUM_OF_CLASSES = 152\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nCUSTOM_WEIGHTS_PATH_1 = \"/kaggle/input/all-folds/birdclef_2022_fold0_epoch_07_f1_val_07180_20240617075011.pth\"\nCUSTOM_WEIGHTS_PATH_2 = \"/kaggle/input/all-folds/birdclef_2022_fold1_epoch_07_f1_val_07197_20240617081511.pth\"\nCUSTOM_WEIGHTS_PATH_3 = \"/kaggle/input/all-folds/birdclef_2022_fold2_epoch_07_f1_val_06874_20240617084017.pth\"\nCUSTOM_WEIGHTS_PATH_4 = \"/kaggle/input/all-folds/birdclef_2022_fold3_epoch_07_f1_val_07346_20240617090522.pth\"\nCUSTOM_WEIGHTS_PATH_5 = \"/kaggle/input/all-folds/birdclef_2022_fold4_epoch_07_f1_val_07627_20240617093029.pth\"\nCUSTOM_WEIGHTS_PATHS = [CUSTOM_WEIGHTS_PATH_1, CUSTOM_WEIGHTS_PATH_2, CUSTOM_WEIGHTS_PATH_4, CUSTOM_WEIGHTS_PATH_5]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:50:02.942293Z","iopub.execute_input":"2024-06-22T15:50:02.942597Z","iopub.status.idle":"2024-06-22T15:50:03.014752Z","shell.execute_reply.started":"2024-06-22T15:50:02.942568Z","shell.execute_reply":"2024-06-22T15:50:03.013810Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Special Dataset Class to handle all test files**","metadata":{}},{"cell_type":"code","source":"class BirdCLEFDataset(Dataset):\n    def __init__(self, data, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n        \n        self.data = data\n        \n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr//2\n\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        \n        self.res_type = res_type\n        self.resample = resample\n\n    def __len__(self):\n        return len(self.data)\n    \n    def compute_mel(self, audio, sr=SR, n_mels=N_MELS, fmin=FMIN, fmax=FMAX, n_fft=N_FFT, hop_length=HOP_LENGTH):\n        melspec = lb.feature.melspectrogram(\n            y=audio,\n            sr=sr, \n            n_mels=n_mels, \n            fmin=fmin, \n            fmax=fmax,\n            n_fft=n_fft,\n            hop_length=hop_length\n        )\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec\n    \n    @staticmethod\n    def normalize(image):\n        image = image.astype(\"float32\", copy=False) / 255.0\n        image = np.stack([image, image, image])\n        return image\n    \n    def audio_to_image(self, audio):\n        melspec = self.compute_mel(audio)\n        image = mono_to_color(melspec)\n        image = self.normalize(image)\n        return image\n\n    def read_file(self, filepath):\n        audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n        \n        #fix streo to mono\n        if np.ndim(audio)>1:\n            audio = np.mean(audio, axis=1)\n\n        if self.resample and orig_sr != self.sr:\n            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n          \n        audios = []\n        for i in range(self.audio_length, len(audio) + self.step, self.step):\n            start = max(0, i - self.audio_length)\n            end = start + self.audio_length\n            audios.append(audio[start:end])\n            \n        if len(audios[-1]) != self.audio_length:\n            audios[-1] = crop_or_pad(audios[-1], self.audio_length)\n            \n        images = [self.audio_to_image(audio) for audio in audios]\n        images = np.stack(images)\n        \n        \n        return images\n    \n        \n    def __getitem__(self, idx):\n        return self.read_file(self.data.loc[idx, \"filepath\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:50:03.016929Z","iopub.execute_input":"2024-06-22T15:50:03.017258Z","iopub.status.idle":"2024-06-22T15:50:03.035189Z","shell.execute_reply.started":"2024-06-22T15:50:03.017232Z","shell.execute_reply":"2024-06-22T15:50:03.034360Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **Helper Functinos**","metadata":{}},{"cell_type":"code","source":"#function to make spectogram better\ndef mono_to_color(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) / (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) / (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\ndef crop_or_pad(y, length):\n    if len(y) < length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n        n_repeats = length // len(y)\n        epsilon = length % len(y)\n        y = np.concatenate([y]*n_repeats + [y[:epsilon]])\n        \n    elif len(y) > length:\n        y = y[:length]\n\n    return y","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:50:03.036316Z","iopub.execute_input":"2024-06-22T15:50:03.036653Z","iopub.status.idle":"2024-06-22T15:50:03.050053Z","shell.execute_reply.started":"2024-06-22T15:50:03.036621Z","shell.execute_reply":"2024-06-22T15:50:03.049366Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#function that fits the model with the custom weights\ndef load_net(checkpoint_path, num_classes=NUM_OF_CLASSES):\n    net = resnest50(pretrained=False)\n    net.fc = nn.Linear(net.fc.in_features, num_classes)\n    dummy_device = torch.device(\"cpu\")\n    d = torch.load(checkpoint_path, map_location=dummy_device)\n    for key in list(d.keys()):\n        d[key.replace(\"model.\", \"\")] = d.pop(key)\n    net.load_state_dict(d)\n    net = net.to(DEVICE)\n    net = net.eval()\n    return net\n\n#function that transforms label based preds to bird name based preds\ndef get_bird_names(preds):\n    bird_names = []\n    for pred in preds:\n        if not pred:\n            bird_names.append(\"nocall\")\n        else:\n            bird_names.append(\" \".join([bird_dict[bird_id] for bird_id in pred]))\n    return bird_names\n\ndef modify_based_on_best(out):\n    top_values = []\n    top_indices = []\n    \n    out_np = out.cpu().numpy()\n    for row in out_np:\n        # Get the indices of the top 3 values\n        indices = np.argsort(row)[-NUM_OF_BEST:][::-1]\n        # Get the top 3 values using these indices\n        values = row[indices]\n        \n        top_values.append(values)\n        top_indices.append(indices)\n        \n    all_values = np.concatenate(top_values)\n    all_indices = np.concatenate(top_indices)\n    top_3_indices = np.argsort(all_values)[-3:][::-1]\n    unique_indices = np.unique(all_indices[top_3_indices])\n\n    for index in unique_indices:\n        out_np[:, index] *= (1+MODIFIER)\n    \n    return torch.from_numpy(out_np)\n\n@torch.no_grad()\n#function that helps the predict process\ndef get_thresh_preds(out, thresh=None):\n    thresh = thresh or THRESH\n    o = (-out).argsort(1)\n    out = modify_based_on_best(out)\n    #npreds = (out > np.percentile(out.cpu().numpy(), PRECENTILE_THRESH)).sum(1)\n    npreds = (out > THRESH).sum(1)\n    preds = []\n    for oo, npred in zip(o, npreds):\n        preds.append(oo[:npred].cpu().numpy().tolist())\n    return preds\n\n#get the final preds on the test data using the model\ndef predict(nets, test_data, names=True):\n    preds = []\n    with torch.no_grad():\n        for idx in list(range(len(test_data))):\n            xb = torch.from_numpy(test_data[idx]).to(DEVICE)\n            pred = 0.\n            for net in nets:\n                o = net(xb)\n                o = torch.sigmoid(o)\n\n                pred += o\n\n            pred /= len(nets)\n            \n            if names:\n                pred = get_bird_names(get_thresh_preds(pred))\n\n            preds.append(pred)\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:50:03.051183Z","iopub.execute_input":"2024-06-22T15:50:03.051487Z","iopub.status.idle":"2024-06-22T15:50:03.067231Z","shell.execute_reply.started":"2024-06-22T15:50:03.051464Z","shell.execute_reply":"2024-06-22T15:50:03.066352Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#function that loads the custom weights to the model and gets the predictions\ndef get_model_results(checkpoints):\n    \n    #create model and use weights\n\n    nets = []\n    for chck in checkpoints:\n        net = load_net(chck, num_classes=NUM_OF_CLASSES)\n        nets.append(net)\n    \n    # get results, first only probs of numerical classes and then convert to bird names\n    preds = predict(nets, test_data, names=True)\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:55:39.611456Z","iopub.execute_input":"2024-06-22T15:55:39.611834Z","iopub.status.idle":"2024-06-22T15:55:39.617580Z","shell.execute_reply.started":"2024-06-22T15:55:39.611805Z","shell.execute_reply":"2024-06-22T15:55:39.616651Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#function to update final dataset that will be used in submission based on model preds\ndef update_PRED(preds, dummy=False):\n    \n    file_list = [f.split('.')[0] for f in sorted(os.listdir(TEST_FOLDER))]\n    num_of_chunks = 12\n\n    if not dummy:\n        for i,afile in enumerate(file_list):\n            file_preds = preds[i]\n    \n            for j in range(num_of_chunks):\n                for bird in scored_birds:\n                    # Assemble the row_id which we need to do for each scored bird\n                    row_id = afile + '_' + bird + '_' + str(5*(j+1))\n                    birds_in_chunk = file_preds[j].split(\" \")\n                \n                    # Put the result into our prediction dict and\n                    PRED['row_id'].append(row_id)\n                    PRED['target'].append(True if bird in birds_in_chunk else False)\n    else:\n        for afile in file_list:\n            for j in range(num_of_chunks):\n                for bird in scored_birds:\n                    row_id = afile + '_' + bird + '_' + str(5*(j+1))\n                    PRED['row_id'].append(row_id)\n                    PRED['target'].append(False)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:55:43.347602Z","iopub.execute_input":"2024-06-22T15:55:43.348562Z","iopub.status.idle":"2024-06-22T15:55:43.360016Z","shell.execute_reply.started":"2024-06-22T15:55:43.348512Z","shell.execute_reply":"2024-06-22T15:55:43.358859Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# **Time to Load the data!**","metadata":{}},{"cell_type":"code","source":"data = pd.DataFrame(\n     [(path.stem, path) for path in Path(TEST_FOLDER).glob(\"*.ogg\")],\n    columns = [\"filename\", \"filepath\"]\n)\n\ntest_data = BirdCLEFDataset(data=data)\n\n#scored birds\nwith open('../input/birdclef-2022/scored_birds.json') as sbfile:\n    scored_birds = json.load(sbfile)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:55:46.394872Z","iopub.execute_input":"2024-06-22T15:55:46.395261Z","iopub.status.idle":"2024-06-22T15:55:46.425248Z","shell.execute_reply.started":"2024-06-22T15:55:46.395230Z","shell.execute_reply":"2024-06-22T15:55:46.424312Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **Predict on test data and update the PRED database**","metadata":{}},{"cell_type":"code","source":"preds = get_model_results(checkpoints=CUSTOM_WEIGHTS_PATHS)\nupdate_PRED(preds)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:55:50.011337Z","iopub.execute_input":"2024-06-22T15:55:50.011714Z","iopub.status.idle":"2024-06-22T15:56:10.220300Z","shell.execute_reply.started":"2024-06-22T15:55:50.011664Z","shell.execute_reply":"2024-06-22T15:56:10.219436Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# **Convert the PRED database to the final submission file**","metadata":{}},{"cell_type":"code","source":"results = pd.DataFrame(PRED, columns = ['row_id', 'target'])\nresults.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T15:56:13.912376Z","iopub.execute_input":"2024-06-22T15:56:13.912952Z","iopub.status.idle":"2024-06-22T15:56:13.936954Z","shell.execute_reply.started":"2024-06-22T15:56:13.912918Z","shell.execute_reply":"2024-06-22T15:56:13.935985Z"},"trusted":true},"execution_count":14,"outputs":[]}]}